# Named Entity Recognition (NER)

## What is NER?
Named Entity Recognition (NER) is a natural language processing (NLP) technique used to identify and classify entities in text into predefined categories such as names of people, organizations, locations, dates, and more.

## Common NER Categories
1. **Person (PERSON)**: Names of people or fictional characters (e.g., "Albert Einstein", "Harry Potter").
2. **Organization (ORG)**: Companies, institutions, or other groups (e.g., "Google", "World Health Organization").
3. **Location (LOC)**: Geographical locations (e.g., "New York", "Mount Everest").
4. **Date (DATE)**: Dates or time-related expressions (e.g., "January 1, 2024", "yesterday").
5. **Time (TIME)**: Specific times (e.g., "3 PM", "noon").
6. **Money (MONEY)**: Monetary values (e.g., "$100", "20 Euros").
7. **Percent (PERCENT)**: Percentage expressions (e.g., "50%", "10 percent").
8. **Facility (FAC)**: Man-made structures or buildings (e.g., "Eiffel Tower", "Golden Gate Bridge").
9. **GPE (Geopolitical Entity)**: Countries, cities, states (e.g., "France", "California").

## How NER Works
1. **Tokenization**: The text is broken down into individual words or tokens.
2. **Part-of-Speech Tagging**: Tags are assigned to each token indicating its part of speech (e.g., noun, verb).
3. **Entity Recognition and Classification**: Identified tokens are classified into one of the predefined categories.

## Applications of NER
- **Information Retrieval**: Extracting relevant data from documents.
- **Chatbots and Virtual Assistants**: Identifying user intents and entities in queries.
- **Content Categorization**: Tagging and classifying articles or news.
- **Automated Summarization**: Extracting key information from large texts.
- **Knowledge Graphs**: Creating linked data by identifying relationships between entities.

## Common NER Tools and Libraries
- **spaCy**: A popular NLP library in Python with built-in NER capabilities.
- **NLTK (Natural Language Toolkit)**: Provides methods for NER, though requires pre-trained models.
- **Stanford NLP**: Offers pre-trained models for NER in multiple languages.
- **Hugging Face Transformers**: Supports advanced NER models based on BERT, GPT, etc.

## Example Code (Using spaCy in Python)
```python
import spacy

# Load the pre-trained NER model
nlp = spacy.load("en_core_web_sm")

# Sample text
text = "Barack Obama was born in Hawaii and served as the President of the United States."

# Process the text
doc = nlp(text)

# Print recognized entities
for ent in doc.ents:
    print(ent.text, ent.label_)
```
### NLTK example:
```python
import nltk
# Sample sentence
sentence = "The Eiffel Tower was built from 1887 to 1889 by Gustave Eiffel, whose company specialized in building metal frameworks and structures."

# Step 1: Tokenize the sentence
words = nltk.word_tokenize(sentence)

# Step 2: POS tagging
tag_elements = nltk.pos_tag(words)

# Step 3: Download the required NLTK models
nltk.download('maxent_ne_chunker') //#Used for named entity chunking
nltk.download('words')

# Step 4: Perform NER and display the result
nltk.ne_chunk(tag_elements).draw() 
```
### Explanation of the Code

-   **Import NLTK**: Import the NLTK library for performing NLP tasks.
-   **Tokenization**: `nltk.word_tokenize(sentence)` splits the sentence into words.
-   **POS Tagging**: `nltk.pos_tag(words)` tags each word with its part of speech.
-   **Downloading Required Models**:
    -   `maxent_ne_chunker`: Used for named entity chunking.
    -   `words`: A word corpus needed for NER.
-   **Perform NER**: `nltk.ne_chunk(tag_elements).draw()` identifies the named entities in the sentence and displays them in a tree structure.

### Output

The code opens a window displaying a tree structure of the entities in the sentence, showing the identified names of people, locations, and other entities.

### Sample Output
For the given sentence, the NER tool will recognize:

-   **Eiffel Tower**: Location
-   **1887**, **1889**: Dates
-   **Gustave Eiffel**: Person
## Challenges in NER

-   **Ambiguity**: Some words can have multiple meanings (e.g., "Apple" as a fruit or a company).
-   **Context Sensitivity**: Understanding the context is crucial for accurate classification.
-   **Domain Adaptation**: NER models trained on general data may not perform well in specialized domains (e.g., medical, legal).

## NER Evaluation Metrics

-   **Precision**: The percentage of correctly identified entities out of all identified entities.
-   **Recall**: The percentage of correctly identified entities out of all true entities in the text.
-   **F1 Score**: The harmonic mean of precision and recall, used as an overall performance metric.
